<h1 align="center"> <p>ğŸ¦š RWKV-PEFT</p></h1>


RWKV-PEFT æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¸º RWKV5/6 æ¨¡å‹å®ç°é«˜æ•ˆå‚æ•°å¾®è°ƒçš„å®˜æ–¹å®ç°ï¼Œæ”¯æŒåœ¨å¤šç§ç¡¬ä»¶ä¸Šå®ç°å¤šç§å…ˆè¿›çš„å¾®è°ƒæ–¹æ³•ã€‚

## ç›®å½•
- [ç¡¬ä»¶éœ€æ±‚](#ç¡¬ä»¶éœ€æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ä¸»è¦ç‰¹æ€§](#ä¸»è¦ç‰¹æ€§)
- [è¯¦ç»†é…ç½®è¯´æ˜](#è¯¦ç»†é…ç½®è¯´æ˜)
- [GPUæ”¯æŒæƒ…å†µ](#gpuæ”¯æŒæƒ…å†µ)
- [å¼•ç”¨](#å¼•ç”¨)

## ç¡¬ä»¶éœ€æ±‚

ä»¥ä¸‹æ˜¯ä½¿ç”¨ RTX 4090 (24GBæ˜¾å­˜) + 64GBå†…å­˜æ—¶çš„æ˜¾å­˜å ç”¨æƒ…å†µï¼ˆå‚æ•°é…ç½®ï¼š`--strategy deepspeed_stage_1 --ctx_len 1024 --micro_bsz 1 --lora_r 64`ï¼‰ï¼š

|   æ¨¡å‹è§„æ¨¡   | å…¨é‡å¾®è°ƒ | LoRA/PISSA | QLoRA/QPISSA | State Tuning |
|-------------|----------|------------|--------------|--------------|
| RWKV6-1.6B  | æ˜¾å­˜æº¢å‡º   | 7.4GB      | 5.6GB        | 6.4GB        |
| RWKV6-3B    | æ˜¾å­˜æº¢å‡º   | 12.1GB     | 8.2GB        | 9.4GB        |
| RWKV6-7B    | æ˜¾å­˜æº¢å‡º   | 23.7GB*    | 14.9GB**     | 18.1GB       |

æ³¨ï¼š
* æ‰¹æ¬¡å¤§å°ä¸º8æ—¶ä¼šæ˜¾å­˜æº¢å‡º
* æ‰¹æ¬¡å¤§å°ä¸º8æ—¶éœ€è¦19.5GBæ˜¾å­˜

## å¿«é€Ÿå¼€å§‹

1. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

2. è¿è¡Œç¤ºä¾‹è„šæœ¬ï¼š
```bash
sh scripts/run_lora.sh
```
æ³¨ï¼šå…·ä½“æ•°æ®å‡†å¤‡æ–¹æ³•è¯·å‚è€ƒRWKVå®˜æ–¹æ•™ç¨‹

3. ä½¿ç”¨ web gui å¼€å§‹ï¼š
> [!TIP]
> å¦‚æœæ‚¨ä½¿ç”¨äº‘æœåŠ¡ (such as [Vast](https://vast.ai/) or [AutoDL](https://www.autodl.com/)), æ‚¨éœ€è¦å‚è€ƒç›¸å…³æœåŠ¡å•†çš„æç¤ºï¼Œå¼€å¯ç½‘é¡µç«¯å£ä¸šåŠ¡ã€‚

```bash
streamlit run web/app.py
```

## ä¸»è¦ç‰¹æ€§

- **å¤šç§å¾®è°ƒæ–¹æ³•**ï¼šæ”¯æŒLoRAã€PISSAã€Bone, State Tuningç­‰
- **é‡åŒ–è®­ç»ƒ**ï¼šæ”¯æŒINT8/NF4é‡åŒ–ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨
- **çµæ´»çš„æ•°æ®åŠ è½½**ï¼šæ”¯æŒå¤šç§æ•°æ®é‡‡æ ·ç­–ç•¥
- **æ˜¾å­˜ä¼˜åŒ–**ï¼šå¤šç§DeepSpeedç­–ç•¥å¯é€‰
- **æŸå¤±Mask**ï¼šæ”¯æŒQAå¯¹è¯å’Œå¡«å……éƒ¨åˆ†çš„æŸå¤±Mask
- **æ— é™é•¿åº¦è®­ç»ƒ**ï¼šæ”¯æŒinfctxè®­ç»ƒæ¨¡å¼, æ­¤æ¨¡å¼åˆ©ç”¨äº†RWKVæ’å®šæ˜¾å­˜å ç”¨çš„ä¼˜åŠ¿ï¼Œåœ¨æœ‰é™çš„èµ„æºä¸‹è®­ç»ƒâ€œæ— é™â€ä¸Šä¸‹æ–‡
- **æ”¯æŒå¤šç§ç¡¬ä»¶**ï¼šç›®å‰ï¼ŒRWKV-PEFT å®˜æ–¹æ”¯æŒ NVIDIA, AMD, æ‘©å°”çº¿ç¨‹ï¼Œæ²æ›¦ï¼Œå¤©æ•°æ™ºèŠ¯ç­‰å¤šç§ç¡¬ä»¶å¹³å°, æ˜‡è…¾NPUçš„å®ç°ä¼šåœ¨åæœŸå®ç°ã€‚æ³¨æ„ï¼šç›®å‰æˆ‘ä»¬åªæ”¯æŒ NVIDIA çš„ issue è¯·æ±‚ã€‚
- **ä½¿ç”¨rwkv-flaé«˜æ•ˆè®­ç»ƒ**: rwkv-flaæ˜¯åŸºäºtritonçš„çº¿æ€§æ³¨æ„åŠ›ç®—å­ï¼Œå¯ä»¥åœ¨ä¸æ”¯æŒcudaçš„ç¡¬ä»¶ä¸Šé«˜æ•ˆç‡è¿è¡Œã€‚

## è¯¦ç»†é…ç½®è¯´æ˜

### 1. PEFTæ–¹æ³•é€‰æ‹©
```bash
--peft bone --bone_config $lora_config
```

### 2. è®­ç»ƒéƒ¨åˆ†é€‰æ‹©
```bash
--train_parts ["time", "ln"]
```
- å¯é€‰éƒ¨åˆ†ï¼šembã€headã€timeã€ln
- é»˜è®¤è®­ç»ƒï¼štimeã€lnï¼ˆå‚æ•°é‡å æ¯”å°ï¼‰

### 3. é‡åŒ–è®­ç»ƒ
```bash
--quant int8/nf4
```

### 4. æ— é™é•¿åº¦è®­ç»ƒï¼ˆinfctxï¼‰
```bash
--train_type infctx --chunk_ctx 512 --ctx_len 2048
```
- ctx_lenï¼šç›®æ ‡è®­ç»ƒé•¿åº¦
- chunk_ctxï¼šåˆ‡ç‰‡é•¿åº¦ï¼Œéœ€å°äºctx_len

### 5. æ•°æ®åŠ è½½ç­–ç•¥
```bash
--dataload pad
```
- getï¼šé»˜è®¤éšæœºé‡‡æ ·ï¼ˆRWKV-LMæ–¹å¼ï¼‰
- padï¼šå›ºå®šé•¿åº¦å¡«å……é‡‡æ ·
- onlyï¼šå•æ¡æ•°æ®é‡‡æ ·ï¼ˆä»…æ”¯æŒbsz=1ï¼‰

### 6. DeepSpeedç­–ç•¥
```bash
--strategy deepspeed_stage_1
```
å¯é€‰ç­–ç•¥ï¼š
- deepspeed_stage_1ï¼šä¼˜å…ˆä½¿ç”¨
- deepspeed_stage_2/3ï¼šå¤§æ¨¡å‹æˆ–å…¨é‡å¾®è°ƒæ—¶ä½¿ç”¨
- deepspeed_stage_2_offload
- deepspeed_stage_3_offload

### 7. FLAç®—å­
é»˜è®¤æƒ…å†µä¸‹ï¼Œ RWKV-PEFT ä¼šä½¿ç”¨è‡ªå®šä¹‰çš„cudaå†…æ ¸æ¥å®ç°wkvè®¡ç®—ã€‚ ä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨`--fla`æ¥å¼€å¯Tritonå†…æ ¸ã€‚
```
--fla
```
## GPUæ”¯æŒæƒ…å†µ

- NVIDIA: CUDA
- Intelã€æ‘©å°”çº¿ç¨‹ã€æ²æ›¦ã€å¤©æ•°æ™ºèŠ¯: FLA, è¿™æ„å‘³ç€ä½ éœ€è¦æ‰‹åŠ¨ä¼ å…¥ `--fla`
- æ˜‡è…¾: CANN(soon)

## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œï¼š

```bibtex
@misc{kang2024boneblockaffinetransformation,
      title={Bone: Block Affine Transformation as Parameter Efficient Fine-tuning Methods for Large Language Models},
      author={Jiale Kang},
      year={2024},
      eprint={2409.15371},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.15371}
}
```